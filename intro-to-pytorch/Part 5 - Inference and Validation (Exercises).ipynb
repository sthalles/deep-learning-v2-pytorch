{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Part 5 - Inference and Validation (Exercises).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%205%20-%20Inference%20and%20Validation%20(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8UDtZvswn3F",
        "colab_type": "text"
      },
      "source": [
        "# Inference and Validation\n",
        "\n",
        "Now that you have a trained network, you can use it for making predictions. This is typically called **inference**, a term borrowed from statistics. However, neural networks have a tendency to perform *too well* on the training data and aren't able to generalize to data that hasn't been seen before. This is called **overfitting** and it impairs inference performance. To test for overfitting while training, we measure the performance on data not in the training set called the **validation** set. We avoid overfitting through regularization such as dropout while monitoring the validation performance during training. In this notebook, I'll show you how to do this in PyTorch. \n",
        "\n",
        "As usual, let's start by loading the dataset through torchvision. You'll learn more about torchvision and loading data in a later part. This time we'll be taking advantage of the test set which you can get by setting `train=False` here:\n",
        "\n",
        "```python\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "```\n",
        "\n",
        "The test set contains images just like the training set. Typically you'll see 10-20% of the original dataset held out for testing and validation with the rest being used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsbNmwozwn3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Llry9xwwn3Z",
        "colab_type": "text"
      },
      "source": [
        "Here I'll create a model like normal, using the same one from my solution for part 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFGHtgVHwn3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYT84XpWwn3g",
        "colab_type": "text"
      },
      "source": [
        "The goal of validation is to measure the model's performance on data that isn't part of the training set. Performance here is up to the developer to define though. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEemnYdzwn3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fdd5062b-c915-460d-f89b-e6677651ef2b"
      },
      "source": [
        "# creates the classifier\n",
        "model = Classifier()\n",
        "\n",
        "# get a batch of data and labels\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "# Get the class probabilities\n",
        "ps = torch.exp(model(images))\n",
        "\n",
        "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
        "print(ps.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([512, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd5w-6Vawn3n",
        "colab_type": "text"
      },
      "source": [
        "With the probabilities, we can get the most likely class using the `ps.topk` method. This returns the $k$ highest values. Since we just want the most likely class, we can use `ps.topk(1)`. This returns a tuple of the top-$k$ values and the top-$k$ indices. If the highest value is the fifth element, we'll get back 4 as the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYJopgpwn3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f168f9e7-2de3-4cf0-f851-e96c2b6b6c97"
      },
      "source": [
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "# Look at the most likely classes for the first 10 examples\n",
        "print(top_class[:10,:])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5],\n",
            "        [5]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrcYaSbiwn3x",
        "colab_type": "text"
      },
      "source": [
        "Now we can check if the predicted classes match the labels. This is simple to do by equating `top_class` and `labels`, but we have to be careful of the shapes. Here `top_class` is a 2D tensor with shape `(64, 1)` while `labels` is 1D with shape `(64)`. To get the equality to work out the way we want, `top_class` and `labels` must have the same shape.\n",
        "\n",
        "If we do\n",
        "\n",
        "```python\n",
        "equals = top_class == labels\n",
        "```\n",
        "\n",
        "`equals` will have shape `(64, 64)`, try it yourself. What it's doing is comparing the one element in each row of `top_class` with each element in `labels` which returns 64 True/False boolean values for each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQQI96MCwn3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "equals = top_class == labels.view(*top_class.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQDByzdCwn32",
        "colab_type": "text"
      },
      "source": [
        "Now we need to calculate the percentage of correct predictions. `equals` has boolean values, either False or True. This means that if we just sum up all the values and divide by the number of values, we get the percentage of correct predictions. This is the same operation as taking the mean, so we can get the accuracy with a call to `torch.mean`. If only it was that simple. If you try `torch.mean(equals)`, you'll get an error\n",
        "\n",
        "```\n",
        "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
        "```\n",
        "\n",
        "This happens because `equals` has type `torch.ByteTensor` but `torch.mean` isn't implemented for tensors with that type. So we'll need to convert `equals` to a float tensor. Note that when we take `torch.mean` it returns a scalar tensor, to get the actual value as a float we'll need to do `accuracy.item()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZL0X4dMwn33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9170672c-291b-41a0-ad55-8924ba4eeae1"
      },
      "source": [
        "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "print(f'Accuracy: {accuracy.item()*100}%')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 9.1796875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDw5TRA2wn38",
        "colab_type": "text"
      },
      "source": [
        "The network is untrained so it's making random guesses and we should see an accuracy around 10%. Now let's train our network and include our validation pass so we can measure how well the network is performing on the test set. Since we're not updating our parameters in the validation pass, we can speed up our code by turning off gradients using `torch.no_grad()`:\n",
        "\n",
        "```python\n",
        "# turn off gradients\n",
        "with torch.no_grad():\n",
        "    # validation pass here\n",
        "    for images, labels in testloader:\n",
        "        ...\n",
        "```\n",
        "\n",
        ">**Exercise:** Implement the validation loop below and print out the total accuracy after the loop. You can largely copy and paste the code from above, but I suggest typing it in because writing it out yourself is essential for building the skill. In general you'll always learn more by typing it rather than copy-pasting. You should be able to get an accuracy above 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAtMyE4swn3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "f8535c4d-9dfd-4a05-a4e1-8c27aa8876f7"
      },
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 30\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "        accuracy = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for i, (x_batch, y_batch) in enumerate(testloader):\n",
        "            logprobs = model(x_batch)\n",
        "            test_loss += criterion(logprobs, y_batch)\n",
        "\n",
        "            probs = torch.exp(logprobs)\n",
        "            _, predictions = probs.topk(1, dim=1)\n",
        "            accuracy += torch.mean((predictions.squeeze() == y_batch).type(torch.FloatTensor))\n",
        "\n",
        "          test_losses.append(test_loss/len(testloader))\n",
        "          train_losses.append(running_loss/len(trainloader))\n",
        "\n",
        "        print(\"Epochs: {}/{}\".format(e+1, epochs),\n",
        "              \"Training loss: {}\".format(running_loss / len(trainloader)),\n",
        "              \"Test loss: {}\".format(test_loss / len(testloader)),\n",
        "              \"Test accuracy: {}\".format(accuracy / len(testloader)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 1/30 Training loss: 0.5088367411799268 Test loss: 0.5259626507759094 Test accuracy: 0.8150390386581421\n",
            "Epochs: 2/30 Training loss: 0.395383391584923 Test loss: 0.41170626878738403 Test accuracy: 0.8484662175178528\n",
            "Epochs: 3/30 Training loss: 0.3526260345252846 Test loss: 0.3983355164527893 Test accuracy: 0.8569393157958984\n",
            "Epochs: 4/30 Training loss: 0.33441421353041745 Test loss: 0.3724563717842102 Test accuracy: 0.8646197319030762\n",
            "Epochs: 5/30 Training loss: 0.31597138805461844 Test loss: 0.3952753245830536 Test accuracy: 0.8572036027908325\n",
            "Epochs: 6/30 Training loss: 0.30240856505024916 Test loss: 0.3581618368625641 Test accuracy: 0.8717141151428223\n",
            "Epochs: 7/30 Training loss: 0.29259873699468336 Test loss: 0.38459616899490356 Test accuracy: 0.865039050579071\n",
            "Epochs: 8/30 Training loss: 0.27949616470253036 Test loss: 0.361917644739151 Test accuracy: 0.8720703125\n",
            "Epochs: 9/30 Training loss: 0.2728759838002069 Test loss: 0.37558552622795105 Test accuracy: 0.8711971044540405\n",
            "Epochs: 10/30 Training loss: 0.26414294732309607 Test loss: 0.3749139904975891 Test accuracy: 0.8729951977729797\n",
            "Epochs: 11/30 Training loss: 0.25934667211732887 Test loss: 0.37061256170272827 Test accuracy: 0.8760110139846802\n",
            "Epochs: 12/30 Training loss: 0.24926871724768299 Test loss: 0.3745312988758087 Test accuracy: 0.878205418586731\n",
            "Epochs: 13/30 Training loss: 0.24612022195654765 Test loss: 0.3822978138923645 Test accuracy: 0.8744600415229797\n",
            "Epochs: 14/30 Training loss: 0.2417564202687824 Test loss: 0.4025796055793762 Test accuracy: 0.8762580752372742\n",
            "Epochs: 15/30 Training loss: 0.24010849683317168 Test loss: 0.38171523809432983 Test accuracy: 0.8820369839668274\n",
            "Epochs: 16/30 Training loss: 0.22968896387069465 Test loss: 0.3979209065437317 Test accuracy: 0.8726562261581421\n",
            "Epochs: 17/30 Training loss: 0.22522306282605445 Test loss: 0.3658772110939026 Test accuracy: 0.8796185255050659\n",
            "Epochs: 18/30 Training loss: 0.2223473607715386 Test loss: 0.3934776782989502 Test accuracy: 0.8833410143852234\n",
            "Epochs: 19/30 Training loss: 0.21948062163442056 Test loss: 0.40130615234375 Test accuracy: 0.874132513999939\n",
            "Epochs: 20/30 Training loss: 0.21103880667626096 Test loss: 0.390781968832016 Test accuracy: 0.8832375407218933\n",
            "Epochs: 21/30 Training loss: 0.20933249368787066 Test loss: 0.4111247658729553 Test accuracy: 0.8796012997627258\n",
            "Epochs: 22/30 Training loss: 0.20537291334540858 Test loss: 0.37232598662376404 Test accuracy: 0.8870347142219543\n",
            "Epochs: 23/30 Training loss: 0.20259165175274998 Test loss: 0.39493441581726074 Test accuracy: 0.8820714950561523\n",
            "Epochs: 24/30 Training loss: 0.1977915367218795 Test loss: 0.3772554099559784 Test accuracy: 0.8848058581352234\n",
            "Epochs: 25/30 Training loss: 0.19029546173206016 Test loss: 0.3947378396987915 Test accuracy: 0.8830021023750305\n",
            "Epochs: 26/30 Training loss: 0.19029466740524908 Test loss: 0.42622774839401245 Test accuracy: 0.8776252865791321\n",
            "Epochs: 27/30 Training loss: 0.19062413269681716 Test loss: 0.3950884938240051 Test accuracy: 0.8843060731887817\n",
            "Epochs: 28/30 Training loss: 0.18691430105440526 Test loss: 0.41514235734939575 Test accuracy: 0.8811006546020508\n",
            "Epochs: 29/30 Training loss: 0.18452688829222721 Test loss: 0.40980690717697144 Test accuracy: 0.8820656538009644\n",
            "Epochs: 30/30 Training loss: 0.18509349596501987 Test loss: 0.4491651654243469 Test accuracy: 0.8829905390739441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZmlRkhpT17s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "aff4278c-d2b3-4179-ab10-3a69e7684e03"
      },
      "source": [
        "plt.plot(train_losses, label=\"train loss\")\n",
        "plt.plot(test_losses, label=\"test loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6688ebc240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFkgYPN9wn4C",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "If we look at the training and validation losses as we train the network, we can see a phenomenon known as overfitting.\n",
        "\n",
        "<img src='https://github.com/sthalles/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/assets/overfitting.png?raw=1' width=450px>\n",
        "\n",
        "The network learns the training set better and better, resulting in lower training losses. However, it starts having problems generalizing to data outside the training set leading to the validation loss increasing. The ultimate goal of any deep learning model is to make predictions on new data, so we should strive to get the lowest validation loss possible. One option is to use the version of the model with the lowest validation loss, here the one around 8-10 training epochs. This strategy is called *early-stopping*. In practice, you'd save the model frequently as you're training then later choose the model with the lowest validation loss.\n",
        "\n",
        "The most common method to reduce overfitting (outside of early-stopping) is *dropout*, where we randomly drop input units. This forces the network to share information between weights, increasing it's ability to generalize to new data. Adding dropout in PyTorch is straightforward using the [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) module.\n",
        "\n",
        "```python\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        # Now with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        \n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x\n",
        "```\n",
        "\n",
        "During training we want to use dropout to prevent overfitting, but during inference we want to use the entire network. So, we need to turn off dropout during validation, testing, and whenever we're using the network to make predictions. To do this, you use `model.eval()`. This sets the model to evaluation mode where the dropout probability is 0. You can turn dropout back on by setting the model to train mode with `model.train()`. In general, the pattern for the validation loop will look like this, where you turn off gradients, set the model to evaluation mode, calculate the validation loss and metric, then set the model back to train mode.\n",
        "\n",
        "```python\n",
        "# turn off gradients\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # validation pass here\n",
        "    for images, labels in testloader:\n",
        "        ...\n",
        "\n",
        "# set model back to train mode\n",
        "model.train()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL6Kox3uwn4D",
        "colab_type": "text"
      },
      "source": [
        "> **Exercise:** Add dropout to your model and train it on Fashion-MNIST again. See if you can get a lower validation loss or higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm8lz0anwn4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO: Define your model with dropout added\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n379rARwn4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "8c4a771f-3162-466d-b940-f7dc68b6bf57"
      },
      "source": [
        "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 30\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "        accuracy = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          # turn model to evaluation mode\n",
        "          model.eval()\n",
        "\n",
        "          for i, (x_batch, y_batch) in enumerate(testloader):\n",
        "            logprobs = model(x_batch)\n",
        "            test_loss += criterion(logprobs, y_batch)\n",
        "\n",
        "            probs = torch.exp(logprobs)\n",
        "            _, predictions = probs.topk(1, dim=1)\n",
        "            accuracy += torch.mean((predictions.squeeze() == y_batch).type(torch.FloatTensor))\n",
        "\n",
        "          test_losses.append(test_loss/len(testloader))\n",
        "          train_losses.append(running_loss/len(trainloader))\n",
        "\n",
        "        print(\"Epochs: {}/{}\".format(e+1, epochs),\n",
        "              \"Training loss: {}\".format(running_loss / len(trainloader)),\n",
        "              \"Test loss: {}\".format(test_loss / len(testloader)),\n",
        "              \"Test accuracy: {}\".format(accuracy / len(testloader)))\n",
        "\n",
        "        # turn the model to training mode\n",
        "        model.train()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 1/30 Training loss: 0.6093374070391726 Test loss: 0.5015403628349304 Test accuracy: 0.8276941180229187\n",
            "Epochs: 2/30 Training loss: 0.48302750818447265 Test loss: 0.46666985750198364 Test accuracy: 0.8263098001480103\n",
            "Epochs: 3/30 Training loss: 0.4532098783485925 Test loss: 0.4233783185482025 Test accuracy: 0.8487017750740051\n",
            "Epochs: 4/30 Training loss: 0.4346880286709586 Test loss: 0.41661620140075684 Test accuracy: 0.8515165448188782\n",
            "Epochs: 5/30 Training loss: 0.4243478239186283 Test loss: 0.4027331471443176 Test accuracy: 0.8569163084030151\n",
            "Epochs: 6/30 Training loss: 0.41766023453174117 Test loss: 0.40788397192955017 Test accuracy: 0.8608972430229187\n",
            "Epochs: 7/30 Training loss: 0.40278987696112345 Test loss: 0.41395172476768494 Test accuracy: 0.8609777688980103\n",
            "Epochs: 8/30 Training loss: 0.39477443845986304 Test loss: 0.3895763158798218 Test accuracy: 0.8623334169387817\n",
            "Epochs: 9/30 Training loss: 0.39196071460017007 Test loss: 0.3944467008113861 Test accuracy: 0.8620519638061523\n",
            "Epochs: 10/30 Training loss: 0.39106812777676814 Test loss: 0.39331579208374023 Test accuracy: 0.868054986000061\n",
            "Epochs: 11/30 Training loss: 0.37857562162156805 Test loss: 0.3838459849357605 Test accuracy: 0.8652229309082031\n",
            "Epochs: 12/30 Training loss: 0.38033514685912934 Test loss: 0.36671337485313416 Test accuracy: 0.870720386505127\n",
            "Epochs: 13/30 Training loss: 0.3707616037524331 Test loss: 0.3905266225337982 Test accuracy: 0.8655847311019897\n",
            "Epochs: 14/30 Training loss: 0.3708646210081288 Test loss: 0.3902914524078369 Test accuracy: 0.8615578413009644\n",
            "Epochs: 15/30 Training loss: 0.38204892223545994 Test loss: 0.40897053480148315 Test accuracy: 0.8584674000740051\n",
            "Epochs: 16/30 Training loss: 0.36858492323965913 Test loss: 0.37910276651382446 Test accuracy: 0.8713005185127258\n",
            "Epochs: 17/30 Training loss: 0.36064258051801845 Test loss: 0.3888552784919739 Test accuracy: 0.8683823347091675\n",
            "Epochs: 18/30 Training loss: 0.36804809820041984 Test loss: 0.39052385091781616 Test accuracy: 0.8620749711990356\n",
            "Epochs: 19/30 Training loss: 0.3600366909001301 Test loss: 0.36410102248191833 Test accuracy: 0.873046875\n",
            "Epochs: 20/30 Training loss: 0.35502795846477503 Test loss: 0.3729568123817444 Test accuracy: 0.8710305094718933\n",
            "Epochs: 21/30 Training loss: 0.35391259360224453 Test loss: 0.36957794427871704 Test accuracy: 0.8707663416862488\n",
            "Epochs: 22/30 Training loss: 0.35575633455536515 Test loss: 0.37268155813217163 Test accuracy: 0.8737190365791321\n",
            "Epochs: 23/30 Training loss: 0.35226382380291854 Test loss: 0.37753817439079285 Test accuracy: 0.8685776591300964\n",
            "Epochs: 24/30 Training loss: 0.35484383428401783 Test loss: 0.36095088720321655 Test accuracy: 0.8740751147270203\n",
            "Epochs: 25/30 Training loss: 0.3516619983893722 Test loss: 0.3764408826828003 Test accuracy: 0.871691107749939\n",
            "Epochs: 26/30 Training loss: 0.34823917679345684 Test loss: 0.3775293529033661 Test accuracy: 0.8700309991836548\n",
            "Epochs: 27/30 Training loss: 0.34631989059894325 Test loss: 0.3811008334159851 Test accuracy: 0.868278980255127\n",
            "Epochs: 28/30 Training loss: 0.3474170612786879 Test loss: 0.3757774829864502 Test accuracy: 0.8681755065917969\n",
            "Epochs: 29/30 Training loss: 0.33959299394253223 Test loss: 0.37786561250686646 Test accuracy: 0.874402642250061\n",
            "Epochs: 30/30 Training loss: 0.34155182047947635 Test loss: 0.37434861063957214 Test accuracy: 0.8710477948188782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJm36NlxSQkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "c172a860-55c6-46cd-aa47-a3bdd21d53a4"
      },
      "source": [
        "plt.plot(train_losses, label=\"train loss\")\n",
        "plt.plot(test_losses, label=\"test loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6688d95860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXwUfkptwn4K",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9I8i7ahwn4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import helper module (should be in the repo)\n",
        "import helper\n",
        "\n",
        "# Test out your network!\n",
        "\n",
        "model.eval()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.view(1, 784)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)\n",
        "\n",
        "# Plot the image and probabilities\n",
        "# helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXUROE4Awn4P",
        "colab_type": "text"
      },
      "source": [
        "## Next Up!\n",
        "\n",
        "In the next part, I'll show you how to save your trained models. In general, you won't want to train a model everytime you need it. Instead, you'll train once, save it, then load the model when you want to train more or use if for inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKDeBOI0RlVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}